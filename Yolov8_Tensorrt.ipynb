{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee562845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·∫£m b·∫£o c√†i ƒë·∫∑t TensorRT\n",
    "# Ki·ªÉm tra NVDIA\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√†i th∆∞ vi·ªán c·ªßa Yolov8 ƒë·ªÉ chuy·ªÉn m√¥ h√¨nh t·ª´ Pytorch sang TensorRT\n",
    "!pip3 install ultralytics[export]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4325620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engine l√† TensorRT, quy tr√¨nh c·ªßa n√≥ v·∫´n l√† t·ª´ Pytorch => ONNX => TensorRT\n",
    "!yolo mode=export model=yolov8n.pt format=engine device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch·∫°y th·ª≠ v·ªõi m√¥ h√¨nh ONNX\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "model = YOLO('yolov8n.onnx')  # t·∫£i m√¥ h√¨nh ONNX\n",
    "result=model('images/image003_4.jpg')[0]  # D∆∞ ƒëo√°n ·∫£nh t·ª´ th∆∞ m·ª•c\n",
    "\n",
    "boxes = result.boxes.xywh.cpu().numpy()  # l·∫•y toa ƒë√¥ c·ªßa boxes \n",
    "probs = result.probs  # l·∫•y x√°c su·∫•t c·ªßa c√°c v√¢t th·ªÉ trong ·∫£nh\n",
    "image_drawed = result.plot()\n",
    "cv2.imwrite(\"result.jpg\",image_drawed) # l∆∞u ·∫£nh xu·ªëng m√°y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4807fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haobk/miniconda3/envs/hao/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'task=segment' or 'task=classify'.\n",
      "Ultralytics YOLOv8.0.49 üöÄ Python-3.10.9 torch-1.11.0+cu102 CUDA:0 (NVIDIA GeForce GTX 1660, 5942MiB)\n",
      "Loading yolov8n.engine for TensorRT inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/04/2023-10:33:13] [TRT] [I] Loaded engine size: 15 MiB\n",
      "[03/04/2023-10:33:13] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +616, GPU +284, now: CPU 1088, GPU 1079 (MiB)\n",
      "[03/04/2023-10:33:13] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.5.0\n",
      "[03/04/2023-10:33:13] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +16, now: CPU 0, GPU 16 (MiB)\n",
      "[03/04/2023-10:33:13] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +32, now: CPU 1073, GPU 1079 (MiB)\n",
      "[03/04/2023-10:33:13] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.5.0\n",
      "[03/04/2023-10:33:13] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +18, now: CPU 0, GPU 34 (MiB)\n",
      "[03/04/2023-10:33:13] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/haobk/Desktop/Mydata/Course/Tensorrt/images/image003_4.jpg: 640x640 5 persons, 3 motorcycles, 2 traffic lights, 1 fire hydrant, 2 umbrellas, 2 potted plants, 4.7ms\n",
      "Speed: 0.5ms preprocess, 4.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ch·∫°y th·ª≠ v·ªõi m√¥ h√¨nh TensorRT\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "model = YOLO('yolov8n.engine')  # t·∫£i m√¥ h√¨nh ONNX\n",
    "result=model('images/image003_4.jpg')[0]  # D∆∞ ƒëo√°n ·∫£nh t·ª´ th∆∞ m·ª•c\n",
    "\n",
    "boxes = result.boxes.xywh.cpu().numpy()  # l·∫•y toa ƒë√¥ c·ªßa boxes \n",
    "probs = result.probs  # l·∫•y x√°c su·∫•t c·ªßa c√°c v√¢t th·ªÉ trong ·∫£nh\n",
    "image_drawed = result.plot()\n",
    "cv2.imwrite(\"result.jpg\",image_drawed) # l∆∞u ·∫£nh xu·ªëng m√°y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7739ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
